{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System für Bibliona\n",
    "\n",
    "**Team:** Sarah Blatz, Ida Krämer, Annika Rathai, Markus Kühnle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Projekt entwickeln wir ein kollaboratives Empfehlungssystem für die Buchplattform Bibliona. Ziel ist es, personalisierte Buchempfehlungen auf Basis vergangener Nutzerbewertungen zu generieren. Wir setzen dabei auf ein bewährtes SVD-Modell (Singular Value Decomposition), das Nutzer- und Item-Latenzfaktoren lernt und daraus individuelle Vorhersagen ableitet.\n",
    "\n",
    "Zu Beginn analysieren wir die Datenqualität, insbesondere mögliche Cold-Start-Probleme und die Nutzbarkeit von Metadaten für contentbasierte Verfahren. Auf Basis dieser Analyse bereinigen wir anschließend das Rating-Set, indem wir zu dünn besetzte Nutzer- und Item-Profile entfernen, und schaffen so eine stabilere Datengrundlage für das Modelltraining. Daraufhin trainieren wir ein SVD-Modell mit festen Hyperparametern und evaluieren dessen Leistung mit klassischen Fehlermaßen wie MAE und RMSE sowie mit Top-N-Metriken wie Precision@K und Recall@K, um die Qualität der generierten Empfehlungen zu bewerten.\n",
    "\n",
    "Das System generiert Top-N-Empfehlungen inklusive Confidence-Score (High/Medium/Low) und einer einfachen Erklärungskomponente, die transparent aufzeigt, wie sich die finale Vorhersage zusammensetzt (globaler Mittelwert + Biases + Interaktion). Damit entsteht ein robustes, nachvollziehbares Empfehlungssystem, das praxisnah für reale Anwendungsszenarien auf der Plattform ausgelegt ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warum SVD statt User-Based und Item-Based Collaborative Filtering?\n",
    "\n",
    "Nach der Analyse verschiedener kollaborativer Filtering-Ansätze haben wir uns für **SVD (Singular Value Decomposition)** entschieden, da es gegenüber klassischen User-Based und Item-Based Methoden entscheidende Vorteile bietet. Während User-Based CF ähnliche Nutzer sucht und deren Bewertungen übernimmt, und Item-Based CF Ähnlichkeiten zwischen Items berechnet, löst SVD das fundamentale Problem der **hohen Dimensionalität und Sparsity** unserer Nutzer-Item-Matrix durch **Latent Factor Modeling**. Das Modell lernt automatisch versteckte Faktoren (z.B. Genre-Präferenzen, Lesestil, Komplexitätsgrad), die Nutzer und Items in einem niedrigdimensionalen Vektorraum repräsentieren. Diese **Latenzfaktoren** ermöglichen es, auch bei extrem spärlichen Daten (wie in unserem Fall mit über 98% Leerwerten in den Metadaten) aussagekräftige Ähnlichkeiten zu finden. Zusätzlich bietet SVD durch die explizite Modellierung von **globalen, Nutzer- und Item-Biases** eine bessere Interpretierbarkeit der Vorhersagen und kann systematische Bewertungsunterschiede zwischen Nutzern (streng vs. großzügig) und Items (beliebt vs. unbekannt) berücksichtigen. Die finale Vorhersage ergibt sich dabei aus der Summe von globalem Durchschnitt, individuellen Biases und der Interaktion zwischen den latenten Nutzer- und Item-Vektoren, was eine transparente Erklärung der Empfehlungen ermöglicht. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.16\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation notwendiger Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPython \u001b[36m3.10.16\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m.venv\u001b[39m\n",
      "Activate with: \u001b[32msource .venv/bin/activate\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!rm -rf .venv # if venv already exists, remove it\n",
    "!uv venv .venv # with pip instead of uv: python -m venv .venv\n",
    "!source .venv/bin/activate # On Windows: .venv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://gitlabci:****@gitlab.sigmalto.com/api/v4/projects/573/packages/pypi/simple, https://pypi.org/simple\n",
      "Requirement already satisfied: ipykernel in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (6.29.5)\n",
      "Requirement already satisfied: notebook in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (7.4.3)\n",
      "Requirement already satisfied: appnope in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipykernel) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipykernel) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipykernel) (8.37.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipykernel) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipykernel) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipykernel) (27.0.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipykernel) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from notebook) (2.16.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from notebook) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.5,>=4.4.3 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from notebook) (4.4.3)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from notebook) (0.2.4)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook) (4.9.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook) (25.1.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook) (3.1.6)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.22.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-server<3,>=2.4.0->notebook) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.3->notebook) (2.0.5)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.3->notebook) (0.28.1)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.3->notebook) (2.2.5)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.3->notebook) (80.9.0)\n",
      "Requirement already satisfied: tomli>=1.2.2 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyterlab<4.5,>=4.4.3->notebook) (2.2.1)\n",
      "Requirement already satisfied: babel>=2.10 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook) (2.17.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook) (4.24.0)\n",
      "Requirement already satisfied: requests>=2.31 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyterlab-server<3,>=2.27.1->notebook) (2.32.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook) (4.14.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook) (21.2.0)\n",
      "Requirement already satisfied: certifi in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab<4.5,>=4.4.3->notebook) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from httpx>=0.25.0->jupyterlab<4.5,>=4.4.3->notebook) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.5,>=4.4.3->notebook) (0.16.0)\n",
      "Requirement already satisfied: decorator in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook) (0.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.8)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (3.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (3.0.0)\n",
      "Requirement already satisfied: uri-template in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (24.11.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (4.13.4)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (3.1.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook) (2.21.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook) (2.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook) (2.7)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook) (2.9.0.20250516)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Installed kernelspec .venv in /Users/markuskuehnle/Library/Jupyter/kernels/.venv\n"
     ]
    }
   ],
   "source": [
    "!pip install ipykernel notebook\n",
    "!python -m ipykernel install --user --name=.venv --display-name \"Python (.venv)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\n",
      "  .venv      /Users/markuskuehnle/Library/Jupyter/kernels/.venv\n",
      "  python3    /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/share/jupyter/kernels/python3\n"
     ]
    }
   ],
   "source": [
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://gitlabci:****@gitlab.sigmalto.com/api/v4/projects/573/packages/pypi/simple, https://pypi.org/simple\n",
      "Requirement already satisfied: numpy==1.26.4 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn==1.7.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: scikit-surprise==1.1.4 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (1.1.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from scikit-learn==1.7.0) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from scikit-learn==1.7.0) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/markuskuehnle/Documents/projects/big-data-recommender/.venv/lib/python3.10/site-packages (from scikit-learn==1.7.0) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install  numpy==1.26.4 scikit-learn==1.7.0 scikit-surprise==1.1.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Set\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datenbeschreibung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "ratings_df: pd.DataFrame = pd.read_csv('../data/Bewertungsmatrix_Bibliona.csv')\n",
    "itemprofile_df: pd.DataFrame = pd.read_csv('../data/Itemprofile_Bibliona.csv')\n",
    "bewertung_df: pd.DataFrame = pd.read_csv('../data/Itemprofile_Bibliona.csv')\n",
    "test_df: pd.DataFrame = pd.read_csv('../data/Testdaten_Bibliona.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Datenqualität besser einzuschätzen, habe ich überprüft, wie viele Bewertungen pro Nutzer vorliegen und wie vollständig die Item-Metadaten sind. Ziel war es zu erkennen, ob Cold-Start-Probleme auftreten könnten und ob sich die Metadaten für contentbasierte Modelle eignen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total users</td>\n",
       "      <td>798.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Users with &lt;10 ratings</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Proportion of users with &lt;10 ratings</td>\n",
       "      <td>0.028822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total metadata features</td>\n",
       "      <td>792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metadata sparsity ratio (0 = dense, 1 = empty)</td>\n",
       "      <td>0.982766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Metric       Value\n",
       "0                                     Total users  798.000000\n",
       "1                          Users with <10 ratings   23.000000\n",
       "2            Proportion of users with <10 ratings    0.028822\n",
       "3                         Total metadata features  792.000000\n",
       "4  Metadata sparsity ratio (0 = dense, 1 = empty)    0.982766"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check 1: Distribution of number of books rated per user\n",
    "user_item_rating_counts: pd.Series = ratings_df.drop(columns=['user_ID']).notna().sum(axis=1)\n",
    "\n",
    "# Check 2: Number of users who rated fewer than 10 books\n",
    "number_of_users_with_less_than_10_ratings: int = (user_item_rating_counts < 10).sum()\n",
    "proportion_of_users_with_less_than_10_ratings: float = (user_item_rating_counts < 10).mean()\n",
    "\n",
    "# Check 3: Sparsity of metadata (proportion of non-zero binary features)\n",
    "binary_feature_columns: list[str] = [col for col in itemprofile_df.columns if col.startswith('Genre_') or col.startswith('Author_')]\n",
    "item_binary_feature_matrix: pd.DataFrame = itemprofile_df[binary_feature_columns].fillna(0)\n",
    "metadata_sparsity_ratio: float = (item_binary_feature_matrix == 0).sum().sum() / item_binary_feature_matrix.size\n",
    "\n",
    "# Prepare results for display\n",
    "statistics_summary_dataframe: pd.DataFrame = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Total users\",\n",
    "        \"Users with <10 ratings\",\n",
    "        \"Proportion of users with <10 ratings\",\n",
    "        \"Total metadata features\",\n",
    "        \"Metadata sparsity ratio (0 = dense, 1 = empty)\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        len(user_item_rating_counts),\n",
    "        number_of_users_with_less_than_10_ratings,\n",
    "        proportion_of_users_with_less_than_10_ratings,\n",
    "        len(binary_feature_columns),\n",
    "        metadata_sparsity_ratio\n",
    "    ]\n",
    "})\n",
    "\n",
    "statistics_summary_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Analyse zeigt: Nur ca. 2,9 % der Nutzer haben weniger als 10 Bewertungen abgegeben, Cold-Start bei Nutzern ist also ein begrenztes Problem. Die Metadaten hingegen sind extrem spärlich (über 98 % Leerwerte), was sie für contentbasierte Ansätze nahezu unbrauchbar macht. Das bestätigt, dass kollaborative Verfahren wie SVD sinnvoller sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unser Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daten laden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird sichergestellt, dass alle vier bereitgestellten Datensätze geladen werden. Das ist die Grundlage für alles Weitere. Wir holen uns die Bewertungen, das Test-Set, das Item-Profil (Bücher mit Features), und die Bewertungsmatrix für Fallbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(\n",
    "    ratings_path: str,\n",
    "    test_path: str,\n",
    "    itemprofile_path: str,\n",
    "    bewertungsmatrix_path: str\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    ratings_df = pd.read_csv(ratings_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    itemprofile_df = pd.read_csv(itemprofile_path)\n",
    "    bewertung_df = pd.read_csv(bewertungsmatrix_path, index_col=0)\n",
    "    return ratings_df, test_df, itemprofile_df, bewertung_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing: Entfernen von zu dünnen Nutzern und Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir filtern alle Nutzer raus, die zu wenige Bewertungen abgegeben haben, und auch Items, die zu selten bewertet wurden. Das verbessert die Trainingsdatenqualität und reduziert Cold-Start-Probleme im Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sparse_users_items(df: pd.DataFrame, user_thresh: int = 10, item_thresh: int = 5) -> pd.DataFrame:\n",
    "    user_counts = df['user_ID'].value_counts()\n",
    "    item_counts = df['item_ID'].value_counts()\n",
    "    return df[\n",
    "        df['user_ID'].isin(user_counts[user_counts >= user_thresh].index) &\n",
    "        df['item_ID'].isin(item_counts[item_counts >= item_thresh].index)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelltraining mit SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird ein kollaboratives Filtermodell auf Basis von SVD (Singular Value Decomposition) trainiert. Die Hyperparameter wurden bewusst fix gesetzt, da wir ohnehin mit einer limitierten Datenbasis arbeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_svd_model(ratings_df: pd.DataFrame) -> Tuple[SVD, Dataset]:\n",
    "    reader = Reader(rating_scale=(1, 10))\n",
    "    data = Dataset.load_from_df(ratings_df[['user_ID', 'item_ID', 'rating']], reader)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_factors': [50],\n",
    "        'n_epochs': [30],\n",
    "        'lr_all': [0.005],\n",
    "        'reg_all': [0.02]\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, joblib_verbose=0)\n",
    "    gs.fit(data)\n",
    "\n",
    "    best_algo = gs.best_estimator['rmse']\n",
    "    trainset = data.build_full_trainset()\n",
    "    best_algo.fit(trainset)\n",
    "\n",
    "    return best_algo, trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Zusatzfunktionen: Confidence + Erklärbarkeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir geben eine einfache Confidence-Stufe für Empfehlungen aus und bieten zusätzlich eine rudimentäre \"Explainability\", d.h. wie sich die Vorhersage zusammensetzt, bestehend aus globalem Durchschnitt, Nutzer- und Item-Bias und Interaktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confidence(score: float) -> str:\n",
    "    if score >= 0.85:\n",
    "        return \"High\"\n",
    "    elif score >= 0.5:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "    \n",
    "    \n",
    "def explain_prediction(algo: SVD, user_id: int, item_id: str) -> Dict[str, float]:\n",
    "    details = {}\n",
    "    try:\n",
    "        user_inner = algo.trainset.to_inner_uid(user_id)\n",
    "        item_inner = algo.trainset.to_inner_iid(item_id)\n",
    "        u_bias = algo.pu[user_inner]\n",
    "        i_bias = algo.qi[item_inner]\n",
    "        pred = algo.predict(user_id, item_id)\n",
    "        details = {\n",
    "            \"global_mean\": algo.trainset.global_mean,\n",
    "            \"user_bias\": algo.bu[user_inner],\n",
    "            \"item_bias\": algo.bi[item_inner],\n",
    "            \"interaction\": np.dot(u_bias, i_bias),\n",
    "            \"final_pred\": pred.est\n",
    "        }\n",
    "    except Exception:\n",
    "        pass\n",
    "    return details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Empfehlungen generieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für einen Nutzer holen wir Top-N Empfehlungen, skalieren die Scores, fügen Confidence und Erklärungen hinzu. Falls Cold Start, nutzen wir die Bewertungsmatrix als Rückfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_recommendations(\n",
    "    algo: SVD,\n",
    "    trainset,\n",
    "    user_id: int,\n",
    "    top_n: int,\n",
    "    bewertung_df: pd.DataFrame,\n",
    "    itemprofile_df: pd.DataFrame\n",
    ") -> List[Tuple[str, float, str, Dict]]:\n",
    "    try:\n",
    "        inner_user_id = trainset.to_inner_uid(user_id)\n",
    "        rated_items = set(trainset.to_raw_iid(iid) for (iid, _) in trainset.ur[inner_user_id])\n",
    "        all_items = set(trainset._raw2inner_id_items.keys())\n",
    "        unseen_items = list(all_items - rated_items)\n",
    "\n",
    "        raw_predictions = [(iid, algo.predict(user_id, iid).est) for iid in unseen_items]\n",
    "        scores = [s for _, s in raw_predictions]\n",
    "        if scores:\n",
    "            scaler = MinMaxScaler()\n",
    "            scaled = scaler.fit_transform(np.array(scores).reshape(-1, 1)).flatten()\n",
    "            enriched_preds = []\n",
    "            for (iid, _), score in zip(raw_predictions, scaled):\n",
    "                confidence = compute_confidence(score)\n",
    "                explanation = explain_prediction(algo, user_id, iid)\n",
    "                enriched_preds.append((iid, score, confidence, explanation))\n",
    "            return sorted(enriched_preds, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        return []\n",
    "    except ValueError:\n",
    "        # Cold-start fallback\n",
    "        if str(user_id) in bewertung_df.index:\n",
    "            fallback = list(bewertung_df.loc[str(user_id)].sort_values(ascending=False).head(top_n).items())\n",
    "            return [(iid, 1.0, \"Low\", {}) for iid, _ in fallback]\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation mit Precision@K, Recall@K, MAE und RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um zu sehen, ob unser Modell etwas taugt, evaluieren wir es mit Metriken wie MAE, RMSE und natürlich Precision@K & Recall@K (für Top-N-Recommendations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(predictions: List[Tuple[str, float, str, Dict]], ground_truth: Set[str], k: int) -> float:\n",
    "    recommended = [item for item, *_ in predictions[:k]]\n",
    "    return len(set(recommended) & ground_truth) / k if k > 0 else 0.0\n",
    "\n",
    "\n",
    "def recall_at_k(predictions: List[Tuple[str, float, str, Dict]], ground_truth: Set[str], k: int) -> float:\n",
    "    recommended = [item for item, *_ in predictions[:k]]\n",
    "    return len(set(recommended) & ground_truth) / len(ground_truth) if ground_truth else 0.0\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    algo: SVD,\n",
    "    test_df: pd.DataFrame,\n",
    "    trainset,\n",
    "    top_k: int,\n",
    "    bewertung_df: pd.DataFrame,\n",
    "    itemprofile_df: pd.DataFrame,\n",
    "    threshold: int = 7\n",
    ") -> Dict[str, float]:\n",
    "    test_preds = []\n",
    "    precision_sum = 0.0\n",
    "    recall_sum = 0.0\n",
    "    user_count = 0\n",
    "\n",
    "    for user_id in test_df[\"user_ID\"].unique():\n",
    "        user_test = test_df[test_df[\"user_ID\"] == user_id]\n",
    "        relevant_items = set(user_test[user_test[\"rating\"] >= threshold][\"item_ID\"])\n",
    "        recommendations = get_top_n_recommendations(algo, trainset, user_id, top_k, bewertung_df, itemprofile_df)\n",
    "\n",
    "        if recommendations and relevant_items:\n",
    "            precision_sum += precision_at_k(recommendations, relevant_items, top_k)\n",
    "            recall_sum += recall_at_k(recommendations, relevant_items, top_k)\n",
    "            user_count += 1\n",
    "\n",
    "        for _, row in user_test.iterrows():\n",
    "            test_preds.append(algo.predict(row[\"user_ID\"], row[\"item_ID\"], row[\"rating\"]))\n",
    "\n",
    "    mae = accuracy.mae(test_preds, verbose=False)\n",
    "    rmse = accuracy.rmse(test_preds, verbose=False)\n",
    "\n",
    "    return {\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Precision@K\": precision_sum / user_count if user_count else 0.0,\n",
    "        \"Recall@K\": recall_sum / user_count if user_count else 0.0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Main Funktion zum Ausführen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier passiert alles: Daten laden, Vorverarbeitung, Training, Evaluation und Anzeigen der Top-Empfehlungen mit Confidence und Erklärung. Ideal für direkte Runs oder als Einstiegspunkt für weitere Tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'MAE': 1.1495580459739365, 'RMSE': 1.543422426495167, 'Precision@K': 0.003913043478260871, 'Recall@K': 0.03096618357487923}\n",
      "\n",
      "Top 10 recommendations for user 243:\n",
      "Item ID: 0553274295, Score: 1.00, Confidence: High\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': -0.057128822772448934, 'item_bias': 1.6337826376951856, 'interaction': -0.004937784997178642, 'final_pred': 9.549020371385403}\n",
      "Item ID: 0345339738, Score: 0.96, Confidence: High\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': -0.057128822772448934, 'item_bias': 1.3101773421786769, 'interaction': 0.10376110915852324, 'final_pred': 9.334113970024594}\n",
      "Item ID: 0440998050, Score: 0.94, Confidence: High\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': -0.057128822772448934, 'item_bias': 1.0111115016620604, 'interaction': 0.2751067554752204, 'final_pred': 9.206393775824676}\n",
      "Item ID: 0812550706, Score: 0.94, Confidence: High\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': -0.057128822772448934, 'item_bias': 1.1427528055181941, 'interaction': 0.13958778777101197, 'final_pred': 9.202516111976601}\n",
      "Item ID: 0439136350, Score: 0.92, Confidence: High\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': -0.057128822772448934, 'item_bias': 0.9245725727034733, 'interaction': 0.2935953545837059, 'final_pred': 9.138343445974574}\n",
      "Item ID: 0446310786, Score: 0.92, Confidence: High\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': -0.057128822772448934, 'item_bias': 1.0065149285046002, 'interaction': 0.1908864614639233, 'final_pred': 9.117576908655918}\n",
      "Item ID: 0451166892, Score: 0.92, Confidence: High\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': -0.057128822772448934, 'item_bias': 0.932537912403294, 'interaction': 0.26118057751201645, 'final_pred': 9.113894008602704}\n",
      "Item ID: 0060987561, Score: 0.91, Confidence: High\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': -0.057128822772448934, 'item_bias': 0.671389655865755, 'interaction': 0.4936972344880015, 'final_pred': 9.085262409041151}\n",
      "Item ID: 0345465083, Score: 0.91, Confidence: High\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': -0.057128822772448934, 'item_bias': 1.0500564338973597, 'interaction': 0.11427668010091356, 'final_pred': 9.084508632685667}\n",
      "Item ID: 055321313X, Score: 0.90, Confidence: High\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': -0.057128822772448934, 'item_bias': 0.9450328655223807, 'interaction': 0.1636780134030823, 'final_pred': 9.028886397612858}\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    ratings_path = '../data/Ratings_Bibliona.csv' # TODO: Pfad zu Ratings angeben\n",
    "    test_path = '../data/Testdaten_Bibliona.csv' # TODO: hier Datensatz zur Evaluation ändern\n",
    "    itemprofile_path = '../data/Itemprofile_Bibliona.csv' # TODO: Pfad zu Itemprofile angeben\n",
    "    bewertung_path = '../data/Bewertungsmatrix_Bibliona.csv' # TODO: Pfad zu Bewertungsmatrix angeben\n",
    "\n",
    "    ratings_df, test_df, itemprofile_df, bewertung_df = load_all_data(\n",
    "        ratings_path, test_path, itemprofile_path, bewertung_path\n",
    "    )\n",
    "\n",
    "    ratings_df = filter_sparse_users_items(ratings_df)\n",
    "    algo, trainset = train_best_svd_model(ratings_df)\n",
    "    metrics = evaluate_model(algo, test_df, trainset, top_k=10,\n",
    "                             bewertung_df=bewertung_df,\n",
    "                             itemprofile_df=itemprofile_df)\n",
    "    print(\"Evaluation Results:\", metrics)\n",
    "\n",
    "    example_user = 243 # TODO: Hier kann die Nutzer-ID für einen beliebigen Nutzer gesetzt werden\n",
    "    recommendations = get_top_n_recommendations(\n",
    "        algo, trainset, example_user, 10, bewertung_df, itemprofile_df\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTop 10 recommendations for user {example_user}:\")\n",
    "    for item_id, score, confidence, explanation in recommendations:\n",
    "        print(f\"Item ID: {item_id}, Score: {score:.2f}, Confidence: {confidence}\")\n",
    "        print(f\"   → Explain: {explanation}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bewertung & Beispielausgabe**\n",
    "\n",
    "Die Evaluierung des SVD-Modells zeigt solide RMSE- und MAE-Werte, allerdings fällt die Precision@K mit 0.0035 und die Recall@K mit 0.0214 eher schwach aus. Das liegt vermutlich an der hohen Item-Vielfalt und sparsamen Nutzer-Item-Matrix, wodurch relevante Empfehlungen schwerer zu treffen sind.\n",
    "\n",
    "Als Beispiel zeigt die Ausgabe für Nutzer 243 zehn Top-Empfehlungen mit hoher Konfidenz. Neben der reinen Score-Normalisierung (0–1) wird jede Empfehlung durch eine einfache \"Explainability\"-Komponente ergänzt: Die finale Vorhersage ergibt sich aus dem globalen Durchschnitt, dem Nutzer-Bias, dem Item-Bias sowie der latenten Interaktion zwischen Nutzer- und Item-Vektor. Dadurch lassen sich Vorhersagen transparenter nachvollziehen, z. B. ob sie eher durch starke Item-Beliebtheit oder durch ein hohes Matching-Profil zwischen Nutzer und Item beeinflusst sind."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
