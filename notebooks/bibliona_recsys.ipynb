{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System für Bibliona\n",
    "\n",
    "**Team:** Sarah Blatz, Ida Krämer, Annika Rathai, Markus Kühnle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Projekt entwickeln wir ein kollaboratives Empfehlungssystem für die Buchplattform Bibliona. Ziel ist es, personalisierte Buchempfehlungen auf Basis vergangener Nutzerbewertungen zu generieren. Wir setzen dabei auf ein bewährtes SVD-Modell (Singular Value Decomposition), das Nutzer- und Item-Latenzfaktoren lernt und daraus individuelle Vorhersagen ableitet.\n",
    "\n",
    "Zu Beginn analysieren wir die Datenqualität, insbesondere mögliche Cold-Start-Probleme und die Nutzbarkeit von Metadaten für contentbasierte Verfahren. Auf Basis dieser Analyse bereinigen wir anschließend das Rating-Set, indem wir zu dünn besetzte Nutzer- und Item-Profile entfernen, und schaffen so eine stabilere Datengrundlage für das Modelltraining. Daraufhin trainieren wir ein SVD-Modell mit festen Hyperparametern und evaluieren dessen Leistung mit klassischen Fehlermaßen wie MAE und RMSE sowie mit Top-N-Metriken wie Precision@K und Recall@K, um die Qualität der generierten Empfehlungen zu bewerten.\n",
    "\n",
    "Das System generiert Top-N-Empfehlungen inklusive Confidence-Score (High/Medium/Low) und einer einfachen Erklärungskomponente, die transparent aufzeigt, wie sich die finale Vorhersage zusammensetzt (globaler Mittelwert + Biases + Interaktion). Damit entsteht ein robustes, nachvollziehbares Empfehlungssystem, das praxisnah für reale Anwendungsszenarien auf der Plattform ausgelegt ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warum SVD statt User-Based und Item-Based Collaborative Filtering?\n",
    "\n",
    "Nach der Analyse verschiedener kollaborativer Filtering-Ansätze haben wir uns für **SVD (Singular Value Decomposition)** entschieden, da es gegenüber klassischen User-Based und Item-Based Methoden entscheidende Vorteile bietet. Während User-Based CF ähnliche Nutzer sucht und deren Bewertungen übernimmt, und Item-Based CF Ähnlichkeiten zwischen Items berechnet, löst SVD das fundamentale Problem der **hohen Dimensionalität und Sparsity** unserer Nutzer-Item-Matrix durch **Latent Factor Modeling**. Das Modell lernt automatisch versteckte Faktoren (z.B. Genre-Präferenzen, Lesestil, Komplexitätsgrad), die Nutzer und Items in einem niedrigdimensionalen Vektorraum repräsentieren. Diese **Latenzfaktoren** ermöglichen es, auch bei extrem spärlichen Daten (wie in unserem Fall mit über 98% Leerwerten in den Metadaten) aussagekräftige Ähnlichkeiten zu finden. Zusätzlich bietet SVD durch die explizite Modellierung von **globalen, Nutzer- und Item-Biases** eine bessere Interpretierbarkeit der Vorhersagen und kann systematische Bewertungsunterschiede zwischen Nutzern (streng vs. großzügig) und Items (beliebt vs. unbekannt) berücksichtigen. Die finale Vorhersage ergibt sich dabei aus der Summe von globalem Durchschnitt, individuellen Biases und der Interaktion zwischen den latenten Nutzer- und Item-Vektoren, was eine transparente Erklärung der Empfehlungen ermöglicht. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.16\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://gitlabci:****@gitlab.sigmalto.com/api/v4/projects/573/packages/pypi/simple, https://pypi.org/simple\n",
      "Requirement already satisfied: numpy==1.26.4 in /Users/markuskuehnle/Documents/projects/bigdata-recsys/.venv/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn==1.7.0 in /Users/markuskuehnle/Documents/projects/bigdata-recsys/.venv/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: scikit-surprise==1.1.4 in /Users/markuskuehnle/Documents/projects/bigdata-recsys/.venv/lib/python3.10/site-packages (1.1.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/markuskuehnle/Documents/projects/bigdata-recsys/.venv/lib/python3.10/site-packages (from scikit-learn==1.7.0) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/markuskuehnle/Documents/projects/bigdata-recsys/.venv/lib/python3.10/site-packages (from scikit-learn==1.7.0) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/markuskuehnle/Documents/projects/bigdata-recsys/.venv/lib/python3.10/site-packages (from scikit-learn==1.7.0) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4 scikit-learn==1.7.0 scikit-surprise==1.1.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Set\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from surprise import Dataset, Reader, SVD, accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "ratings_df: pd.DataFrame = pd.read_csv('../data/Bewertungsmatrix_Bibliona.csv')\n",
    "itemprofile_df: pd.DataFrame = pd.read_csv('../data/Itemprofile_Bibliona.csv')\n",
    "bewertung_df: pd.DataFrame = pd.read_csv('../data/Itemprofile_Bibliona.csv')\n",
    "test_df: pd.DataFrame = pd.read_csv('../data/Testdaten_Bibliona.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_ID</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Publication_Year</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Author_(mei) Kan, fei er de</th>\n",
       "      <th>Author_A. A. Milne</th>\n",
       "      <th>Author_A. Manette Ansay</th>\n",
       "      <th>Author_A. S. Byatt</th>\n",
       "      <th>Author_AMY TAN</th>\n",
       "      <th>...</th>\n",
       "      <th>Genre_literary fiction</th>\n",
       "      <th>Genre_open_syllabus_project</th>\n",
       "      <th>Genre_orphans</th>\n",
       "      <th>Genre_psychological fiction</th>\n",
       "      <th>Genre_science fiction</th>\n",
       "      <th>Genre_suicide</th>\n",
       "      <th>Genre_suspense</th>\n",
       "      <th>Genre_suspense fiction</th>\n",
       "      <th>Genre_thrillers</th>\n",
       "      <th>Genre_Écoles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0440234743</td>\n",
       "      <td>The Testament</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Dell</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0452264464</td>\n",
       "      <td>Beloved (Plume Contemporary Fiction)</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>Plume</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0971880107</td>\n",
       "      <td>Wild Animus</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Too Far</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0345402871</td>\n",
       "      <td>Airframe</td>\n",
       "      <td>431.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0345417623</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 797 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_ID                            Book-Title  Pages  Publication_Year  \\\n",
       "0  0440234743                         The Testament    NaN            2000.0   \n",
       "1  0452264464  Beloved (Plume Contemporary Fiction)  275.0            1988.0   \n",
       "2  0971880107                           Wild Animus  315.0            2004.0   \n",
       "3  0345402871                              Airframe  431.0            1997.0   \n",
       "4  0345417623                              Timeline  496.0            2000.0   \n",
       "\n",
       "          Publisher  Author_(mei) Kan, fei er de  Author_A. A. Milne  \\\n",
       "0              Dell                            0                   0   \n",
       "1             Plume                            0                   0   \n",
       "2           Too Far                            0                   0   \n",
       "3  Ballantine Books                            0                   0   \n",
       "4  Ballantine Books                            0                   0   \n",
       "\n",
       "   Author_A. Manette Ansay  Author_A. S. Byatt  Author_AMY TAN  ...  \\\n",
       "0                        0                   0               0  ...   \n",
       "1                        0                   0               0  ...   \n",
       "2                        0                   0               0  ...   \n",
       "3                        0                   0               0  ...   \n",
       "4                        0                   0               0  ...   \n",
       "\n",
       "   Genre_literary fiction  Genre_open_syllabus_project  Genre_orphans  \\\n",
       "0                       0                            0              0   \n",
       "1                       0                            0              0   \n",
       "2                       0                            0              0   \n",
       "3                       0                            0              0   \n",
       "4                       0                            0              0   \n",
       "\n",
       "   Genre_psychological fiction  Genre_science fiction  Genre_suicide  \\\n",
       "0                            0                      0              0   \n",
       "1                            0                      0              0   \n",
       "2                            0                      0              0   \n",
       "3                            0                      0              0   \n",
       "4                            0                      0              0   \n",
       "\n",
       "   Genre_suspense  Genre_suspense fiction  Genre_thrillers  Genre_Écoles  \n",
       "0               0                       0                0             0  \n",
       "1               0                       0                0             0  \n",
       "2               0                       0                0             0  \n",
       "3               0                       0                0             0  \n",
       "4               0                       0                0             0  \n",
       "\n",
       "[5 rows x 797 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemprofile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_ID</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Pages</th>\n",
       "      <th>Publication_Year</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Author_(mei) Kan, fei er de</th>\n",
       "      <th>Author_A. A. Milne</th>\n",
       "      <th>Author_A. Manette Ansay</th>\n",
       "      <th>Author_A. S. Byatt</th>\n",
       "      <th>Author_AMY TAN</th>\n",
       "      <th>...</th>\n",
       "      <th>Genre_literary fiction</th>\n",
       "      <th>Genre_open_syllabus_project</th>\n",
       "      <th>Genre_orphans</th>\n",
       "      <th>Genre_psychological fiction</th>\n",
       "      <th>Genre_science fiction</th>\n",
       "      <th>Genre_suicide</th>\n",
       "      <th>Genre_suspense</th>\n",
       "      <th>Genre_suspense fiction</th>\n",
       "      <th>Genre_thrillers</th>\n",
       "      <th>Genre_Écoles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0440234743</td>\n",
       "      <td>The Testament</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Dell</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0452264464</td>\n",
       "      <td>Beloved (Plume Contemporary Fiction)</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>Plume</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0971880107</td>\n",
       "      <td>Wild Animus</td>\n",
       "      <td>315.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Too Far</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0345402871</td>\n",
       "      <td>Airframe</td>\n",
       "      <td>431.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0345417623</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 797 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_ID                            Book-Title  Pages  Publication_Year  \\\n",
       "0  0440234743                         The Testament    NaN            2000.0   \n",
       "1  0452264464  Beloved (Plume Contemporary Fiction)  275.0            1988.0   \n",
       "2  0971880107                           Wild Animus  315.0            2004.0   \n",
       "3  0345402871                              Airframe  431.0            1997.0   \n",
       "4  0345417623                              Timeline  496.0            2000.0   \n",
       "\n",
       "          Publisher  Author_(mei) Kan, fei er de  Author_A. A. Milne  \\\n",
       "0              Dell                            0                   0   \n",
       "1             Plume                            0                   0   \n",
       "2           Too Far                            0                   0   \n",
       "3  Ballantine Books                            0                   0   \n",
       "4  Ballantine Books                            0                   0   \n",
       "\n",
       "   Author_A. Manette Ansay  Author_A. S. Byatt  Author_AMY TAN  ...  \\\n",
       "0                        0                   0               0  ...   \n",
       "1                        0                   0               0  ...   \n",
       "2                        0                   0               0  ...   \n",
       "3                        0                   0               0  ...   \n",
       "4                        0                   0               0  ...   \n",
       "\n",
       "   Genre_literary fiction  Genre_open_syllabus_project  Genre_orphans  \\\n",
       "0                       0                            0              0   \n",
       "1                       0                            0              0   \n",
       "2                       0                            0              0   \n",
       "3                       0                            0              0   \n",
       "4                       0                            0              0   \n",
       "\n",
       "   Genre_psychological fiction  Genre_science fiction  Genre_suicide  \\\n",
       "0                            0                      0              0   \n",
       "1                            0                      0              0   \n",
       "2                            0                      0              0   \n",
       "3                            0                      0              0   \n",
       "4                            0                      0              0   \n",
       "\n",
       "   Genre_suspense  Genre_suspense fiction  Genre_thrillers  Genre_Écoles  \n",
       "0               0                       0                0             0  \n",
       "1               0                       0                0             0  \n",
       "2               0                       0                0             0  \n",
       "3               0                       0                0             0  \n",
       "4               0                       0                0             0  \n",
       "\n",
       "[5 rows x 797 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bewertung_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ID</th>\n",
       "      <th>002542730X</th>\n",
       "      <th>0060096195</th>\n",
       "      <th>006016848X</th>\n",
       "      <th>0060173289</th>\n",
       "      <th>0060175400</th>\n",
       "      <th>0060188731</th>\n",
       "      <th>006019491X</th>\n",
       "      <th>0060199652</th>\n",
       "      <th>0060391626</th>\n",
       "      <th>...</th>\n",
       "      <th>1573221937</th>\n",
       "      <th>1573225517</th>\n",
       "      <th>1573225789</th>\n",
       "      <th>1573227331</th>\n",
       "      <th>1573228214</th>\n",
       "      <th>1573229326</th>\n",
       "      <th>1573229571</th>\n",
       "      <th>1576737330</th>\n",
       "      <th>1592400876</th>\n",
       "      <th>1878424319</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 782 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_ID  002542730X  0060096195  006016848X  0060173289  0060175400  \\\n",
       "0      243         NaN         NaN         NaN         NaN         NaN   \n",
       "1      254         NaN         NaN         NaN         NaN         NaN   \n",
       "2      638         NaN         NaN         NaN         NaN         NaN   \n",
       "3     1131         NaN         NaN         NaN         NaN         NaN   \n",
       "4     1435         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   0060188731  006019491X  0060199652  0060391626  ...  1573221937  \\\n",
       "0         NaN         NaN         NaN         NaN  ...         NaN   \n",
       "1         NaN         NaN         NaN         NaN  ...         NaN   \n",
       "2         NaN         NaN         NaN         NaN  ...         NaN   \n",
       "3         NaN         NaN         NaN         NaN  ...         NaN   \n",
       "4         NaN         NaN         NaN         NaN  ...         NaN   \n",
       "\n",
       "   1573225517  1573225789  1573227331  1573228214  1573229326  1573229571  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   1576737330  1592400876  1878424319  \n",
       "0         NaN         NaN         NaN  \n",
       "1         NaN         NaN         NaN  \n",
       "2         NaN         NaN         NaN  \n",
       "3         NaN         NaN         NaN  \n",
       "4         NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 782 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Datenqualität besser einzuschätzen, habe ich überprüft, wie viele Bewertungen pro Nutzer vorliegen und wie vollständig die Item-Metadaten sind. Ziel war es zu erkennen, ob Cold-Start-Probleme auftreten könnten und ob sich die Metadaten für contentbasierte Modelle eignen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total users</td>\n",
       "      <td>798.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Users with &lt;10 ratings</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Proportion of users with &lt;10 ratings</td>\n",
       "      <td>0.028822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Total metadata features</td>\n",
       "      <td>792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metadata sparsity ratio (0 = dense, 1 = empty)</td>\n",
       "      <td>0.982766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Metric       Value\n",
       "0                                     Total users  798.000000\n",
       "1                          Users with <10 ratings   23.000000\n",
       "2            Proportion of users with <10 ratings    0.028822\n",
       "3                         Total metadata features  792.000000\n",
       "4  Metadata sparsity ratio (0 = dense, 1 = empty)    0.982766"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check 1: Distribution of number of books rated per user\n",
    "user_item_rating_counts: pd.Series = ratings_df.drop(columns=['user_ID']).notna().sum(axis=1)\n",
    "\n",
    "# Check 2: Number of users who rated fewer than 10 books\n",
    "number_of_users_with_less_than_10_ratings: int = (user_item_rating_counts < 10).sum()\n",
    "proportion_of_users_with_less_than_10_ratings: float = (user_item_rating_counts < 10).mean()\n",
    "\n",
    "# Check 3: Sparsity of metadata (proportion of non-zero binary features)\n",
    "binary_feature_columns: list[str] = [col for col in itemprofile_df.columns if col.startswith('Genre_') or col.startswith('Author_')]\n",
    "item_binary_feature_matrix: pd.DataFrame = itemprofile_df[binary_feature_columns].fillna(0)\n",
    "metadata_sparsity_ratio: float = (item_binary_feature_matrix == 0).sum().sum() / item_binary_feature_matrix.size\n",
    "\n",
    "# Prepare results for display\n",
    "statistics_summary_dataframe: pd.DataFrame = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Total users\",\n",
    "        \"Users with <10 ratings\",\n",
    "        \"Proportion of users with <10 ratings\",\n",
    "        \"Total metadata features\",\n",
    "        \"Metadata sparsity ratio (0 = dense, 1 = empty)\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        len(user_item_rating_counts),\n",
    "        number_of_users_with_less_than_10_ratings,\n",
    "        proportion_of_users_with_less_than_10_ratings,\n",
    "        len(binary_feature_columns),\n",
    "        metadata_sparsity_ratio\n",
    "    ]\n",
    "})\n",
    "\n",
    "statistics_summary_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Analyse zeigt: Nur ca. 2,9 % der Nutzer haben weniger als 10 Bewertungen abgegeben, Cold-Start bei Nutzern ist also ein begrenztes Problem. Die Metadaten hingegen sind extrem spärlich (über 98 % Leerwerte), was sie für contentbasierte Ansätze nahezu unbrauchbar macht. Das bestätigt, dass kollaborative Verfahren wie SVD sinnvoller sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unser Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daten laden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird sichergestellt, dass alle vier bereitgestellten Datensätze geladen werden. Das ist die Grundlage für alles Weitere. Wir holen uns die Bewertungen, das Test-Set, das Item-Profil (Bücher mit Features), und die Bewertungsmatrix für Fallbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(\n",
    "    ratings_path: str,\n",
    "    test_path: str,\n",
    "    itemprofile_path: str,\n",
    "    bewertungsmatrix_path: str\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    ratings_df = pd.read_csv(ratings_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    itemprofile_df = pd.read_csv(itemprofile_path)\n",
    "    bewertung_df = pd.read_csv(bewertungsmatrix_path, index_col=0)\n",
    "    return ratings_df, test_df, itemprofile_df, bewertung_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing: Entfernen von zu dünnen Nutzern und Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir filtern alle Nutzer raus, die zu wenige Bewertungen abgegeben haben, und auch Items, die zu selten bewertet wurden. Das verbessert die Trainingsdatenqualität und reduziert Cold-Start-Probleme im Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sparse_users_items(df: pd.DataFrame, user_thresh: int = 10, item_thresh: int = 5) -> pd.DataFrame:\n",
    "    user_counts = df['user_ID'].value_counts()\n",
    "    item_counts = df['item_ID'].value_counts()\n",
    "    return df[\n",
    "        df['user_ID'].isin(user_counts[user_counts >= user_thresh].index) &\n",
    "        df['item_ID'].isin(item_counts[item_counts >= item_thresh].index)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelltraining mit SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird ein kollaboratives Filtermodell auf Basis von SVD (Singular Value Decomposition) trainiert. Die Hyperparameter wurden bewusst fix gesetzt, da wir ohnehin mit einer limitierten Datenbasis arbeiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_svd_model(ratings_df: pd.DataFrame) -> Tuple[SVD, Dataset]:\n",
    "    reader = Reader(rating_scale=(1, 10))\n",
    "    data = Dataset.load_from_df(ratings_df[['user_ID', 'item_ID', 'rating']], reader)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_factors': [50],\n",
    "        'n_epochs': [30],\n",
    "        'lr_all': [0.005],\n",
    "        'reg_all': [0.02]\n",
    "    }\n",
    "\n",
    "    gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3, joblib_verbose=0)\n",
    "    gs.fit(data)\n",
    "\n",
    "    best_algo = gs.best_estimator['rmse']\n",
    "    trainset = data.build_full_trainset()\n",
    "    best_algo.fit(trainset)\n",
    "\n",
    "    return best_algo, trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Zusatzfunktionen: Confidence + Erklärbarkeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir geben eine einfache Confidence-Stufe für Empfehlungen aus und bieten zusätzlich eine rudimentäre \"Explainability\", d.h. wie sich die Vorhersage zusammensetzt, bestehend aus globalem Durchschnitt, Nutzer- und Item-Bias und Interaktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confidence(score: float) -> str:\n",
    "    if score >= 0.85:\n",
    "        return \"High\"\n",
    "    elif score >= 0.5:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "    \n",
    "    \n",
    "def explain_prediction(algo: SVD, user_id: int, item_id: str) -> Dict[str, float]:\n",
    "    details = {}\n",
    "    try:\n",
    "        user_inner = algo.trainset.to_inner_uid(user_id)\n",
    "        item_inner = algo.trainset.to_inner_iid(item_id)\n",
    "        u_bias = algo.pu[user_inner]\n",
    "        i_bias = algo.qi[item_inner]\n",
    "        pred = algo.predict(user_id, item_id)\n",
    "        details = {\n",
    "            \"global_mean\": algo.trainset.global_mean,\n",
    "            \"user_bias\": algo.bu[user_inner],\n",
    "            \"item_bias\": algo.bi[item_inner],\n",
    "            \"interaction\": np.dot(u_bias, i_bias),\n",
    "            \"final_pred\": pred.est\n",
    "        }\n",
    "    except Exception:\n",
    "        pass\n",
    "    return details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Empfehlungen generieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für einen Nutzer holen wir Top-N Empfehlungen, skalieren die Scores, fügen Confidence und Erklärungen hinzu. Falls Cold Start, nutzen wir die Bewertungsmatrix als Rückfall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_recommendations(\n",
    "    algo: SVD,\n",
    "    trainset,\n",
    "    user_id: int,\n",
    "    top_n: int,\n",
    "    bewertung_df: pd.DataFrame,\n",
    "    itemprofile_df: pd.DataFrame\n",
    ") -> List[Tuple[str, float, str, Dict, Dict[str, str]]]:\n",
    "    \"\"\"\n",
    "    Generate top-N recommendations for a user, including confidence, explanation, and selected metadata.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        inner_user_id: int = trainset.to_inner_uid(user_id)\n",
    "        rated_items: set[str] = set(trainset.to_raw_iid(iid) for (iid, _) in trainset.ur[inner_user_id])\n",
    "        all_items: set[str] = set(trainset._raw2inner_id_items.keys())\n",
    "        unseen_items: list[str] = list(all_items - rated_items)\n",
    "\n",
    "        # Generate predictions for all unseen items\n",
    "        predictions: list[Tuple[str, float]] = []\n",
    "        for item_id in unseen_items:\n",
    "            pred = algo.predict(user_id, item_id)\n",
    "            predictions.append((item_id, pred.est))\n",
    "\n",
    "        scores: list[float] = [score for _, score in predictions]\n",
    "        if scores:\n",
    "            scaler: MinMaxScaler = MinMaxScaler()\n",
    "            scaled_scores: np.ndarray = scaler.fit_transform(np.array(scores).reshape(-1, 1)).flatten()\n",
    "            enriched_predictions: list[Tuple[str, float, str, Dict, Dict[str, str]]] = []\n",
    "            for (item_id, _), scaled_score in zip(predictions, scaled_scores):\n",
    "                confidence: str = compute_confidence(scaled_score)\n",
    "                explanation: Dict = explain_prediction(algo, user_id, item_id)\n",
    "                # Lookup metadata\n",
    "                book_row: Optional[pd.Series] = itemprofile_df.loc[itemprofile_df['item_ID'] == item_id].squeeze() if not itemprofile_df[itemprofile_df['item_ID'] == item_id].empty else None\n",
    "                metadata: Dict[str, str] = {\n",
    "                    'Book-Title': book_row['Book-Title'] if book_row is not None and 'Book-Title' in book_row else 'Unknown',\n",
    "                    'Publication_Year': book_row['Publication_Year'] if book_row is not None and 'Publication_Year' in book_row else 'Unknown',\n",
    "                    'Publisher': book_row['Publisher'] if book_row is not None and 'Publisher' in book_row else 'Unknown'\n",
    "                }\n",
    "                enriched_predictions.append((item_id, scaled_score, confidence, explanation, metadata))\n",
    "            return sorted(enriched_predictions, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        return []\n",
    "    except ValueError:\n",
    "        # Cold-start fallback\n",
    "        if str(user_id) in bewertung_df.index:\n",
    "            fallback: list[Tuple[str, float]] = list(bewertung_df.loc[str(user_id)].sort_values(ascending=False).head(top_n).items())\n",
    "            fallback_recommendations: list[Tuple[str, float, str, Dict, Dict[str, str]]] = []\n",
    "            for iid, _ in fallback:\n",
    "                book_row: Optional[pd.Series] = itemprofile_df.loc[itemprofile_df['item_ID'] == iid].squeeze() if not itemprofile_df[itemprofile_df['item_ID'] == iid].empty else None\n",
    "                metadata: Dict[str, str] = {\n",
    "                    'Book-Title': book_row['Book-Title'] if book_row is not None and 'Book-Title' in book_row else 'Unknown',\n",
    "                    'Publication_Year': book_row['Publication_Year'] if book_row is not None and 'Publication_Year' in book_row else 'Unknown',\n",
    "                    'Publisher': book_row['Publisher'] if book_row is not None and 'Publisher' in book_row else 'Unknown'\n",
    "                }\n",
    "                fallback_recommendations.append((iid, 1.0, \"Low\", {}, metadata))\n",
    "            return fallback_recommendations\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation mit Precision@K, Recall@K, MAE und RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um zu sehen, ob unser Modell etwas taugt, evaluieren wir es mit Metriken wie MAE, RMSE und natürlich Precision@K & Recall@K (für Top-N-Recommendations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(predictions: List[Tuple[str, float, str, Dict]], ground_truth: Set[str], k: int) -> float:\n",
    "    recommended = [item for item, *_ in predictions[:k]]\n",
    "    return len(set(recommended) & ground_truth) / k if k > 0 else 0.0\n",
    "\n",
    "\n",
    "def recall_at_k(predictions: List[Tuple[str, float, str, Dict]], ground_truth: Set[str], k: int) -> float:\n",
    "    recommended = [item for item, *_ in predictions[:k]]\n",
    "    return len(set(recommended) & ground_truth) / len(ground_truth) if ground_truth else 0.0\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    algo: SVD,\n",
    "    test_df: pd.DataFrame,\n",
    "    trainset,\n",
    "    top_k: int,\n",
    "    bewertung_df: pd.DataFrame,\n",
    "    itemprofile_df: pd.DataFrame,\n",
    "    threshold: int = 7\n",
    ") -> Dict[str, float]:\n",
    "    test_preds = []\n",
    "    precision_sum = 0.0\n",
    "    recall_sum = 0.0\n",
    "    user_count = 0\n",
    "\n",
    "    for user_id in test_df[\"user_ID\"].unique():\n",
    "        user_test = test_df[test_df[\"user_ID\"] == user_id]\n",
    "        relevant_items = set(user_test[user_test[\"rating\"] >= threshold][\"item_ID\"])\n",
    "        recommendations = get_top_n_recommendations(algo, trainset, user_id, top_k, bewertung_df, itemprofile_df)\n",
    "\n",
    "        if recommendations and relevant_items:\n",
    "            precision_sum += precision_at_k(recommendations, relevant_items, top_k)\n",
    "            recall_sum += recall_at_k(recommendations, relevant_items, top_k)\n",
    "            user_count += 1\n",
    "\n",
    "        for _, row in user_test.iterrows():\n",
    "            test_preds.append(algo.predict(row[\"user_ID\"], row[\"item_ID\"], row[\"rating\"]))\n",
    "\n",
    "    mae = accuracy.mae(test_preds, verbose=False)\n",
    "    rmse = accuracy.rmse(test_preds, verbose=False)\n",
    "\n",
    "    return {\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Precision@K\": precision_sum / user_count if user_count else 0.0,\n",
    "        \"Recall@K\": recall_sum / user_count if user_count else 0.0\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Main Funktion zum Ausführen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier passiert alles: Daten laden, Vorverarbeitung, Training, Evaluation und Anzeigen der Top-Empfehlungen mit Confidence und Erklärung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'MAE': 1.1471790595145435, 'RMSE': 1.5410261215589736, 'Precision@K': 0.004057971014492756, 'Recall@K': 0.03060386473429952}\n",
      "\n",
      "Top 10 recommendations for user 243:\n",
      "Item ID: 0553274295, Score: 1.00, Confidence: High\n",
      "   Title: Where the Red Fern Grows\n",
      "   Year: 2016, Publisher: Random House Children's Books\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': 0.01270329484449787, 'item_bias': 1.6418491560626969, 'interaction': 0.14225697706676954, 'final_pred': 9.774113769433809}\n",
      "Item ID: 0345339738, Score: 0.94, Confidence: High\n",
      "   Title: The Return of the King (The Lord of the Rings, Part 3)\n",
      "   Year: 1986, Publisher: Del Rey\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': 0.01270329484449787, 'item_bias': 1.321671797937582, 'interaction': 0.12699399212359982, 'final_pred': 9.438673426365524}\n",
      "Item ID: 0446310786, Score: 0.91, Confidence: High\n",
      "   Title: To Kill a Mockingbird\n",
      "   Year: 1993, Publisher: Little Brown & Company\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': 0.01270329484449787, 'item_bias': 0.994944366726078, 'interaction': 0.3223539166381699, 'final_pred': 9.30730591966859}\n",
      "Item ID: 0345361792, Score: 0.89, Confidence: High\n",
      "   Title: A Prayer for Owen Meany\n",
      "   Year: 1990, Publisher: Ballantine Books\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': 0.01270329484449787, 'item_bias': 1.0797546541605776, 'interaction': 0.12947519594509732, 'final_pred': 9.199237486410016}\n",
      "Item ID: 0812550706, Score: 0.89, Confidence: High\n",
      "   Title: Ender's Game (Ender Wiggins Saga (Paperback))\n",
      "   Year: 2013, Publisher: Tor Books\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': 0.01270329484449787, 'item_bias': 1.0634709832865143, 'interaction': 0.11186594257452455, 'final_pred': 9.165344562165382}\n",
      "Item ID: 0877017883, Score: 0.89, Confidence: High\n",
      "   Title: Griffin & Sabine: An Extraordinary Correspondence\n",
      "   Year: 1991, Publisher: Chronicle Books\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': 0.01270329484449787, 'item_bias': 1.14540827626748, 'interaction': 0.026897050685567244, 'final_pred': 9.16231296325739}\n",
      "Item ID: 0553573403, Score: 0.88, Confidence: High\n",
      "   Title: A Game of Thrones (A Song of Ice and Fire, Book 1)\n",
      "   Year: 2011, Publisher: Spectra Books\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': 0.01270329484449787, 'item_bias': 0.9520238417208304, 'interaction': 0.19726110223704088, 'final_pred': 9.139292580262213}\n",
      "Item ID: 0312195516, Score: 0.88, Confidence: High\n",
      "   Title: The Red Tent (Bestselling Backlist)\n",
      "   Year: 1997, Publisher: Picador USA\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': 0.01270329484449787, 'item_bias': 0.6864965068054458, 'interaction': 0.4444113762108604, 'final_pred': 9.120915519320649}\n",
      "Item ID: 0679723161, Score: 0.88, Confidence: High\n",
      "   Title: Lolita (Vintage International)\n",
      "   Year: 1997, Publisher: Vintage\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': 0.01270329484449787, 'item_bias': 1.1570895316399477, 'interaction': -0.04101395793017446, 'final_pred': 9.106083210014116}\n",
      "Item ID: 0451166892, Score: 0.87, Confidence: High\n",
      "   Title: The Pillars of the Earth\n",
      "   Year: 2001, Publisher: Signet Book\n",
      "   → Explain: {'global_mean': 7.977304341459844, 'user_bias': 0.01270329484449787, 'item_bias': 0.912034663616187, 'interaction': 0.16694108314459521, 'final_pred': 9.068983383065124}\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    ratings_path = '../data/Ratings_Bibliona.csv' # TODO: Pfad zu Ratings angeben\n",
    "    test_path = '../data/Testdaten_Bibliona.csv' # TODO: hier Datensatz zur Evaluation ändern\n",
    "    itemprofile_path = '../data/Itemprofile_Bibliona.csv' # TODO: Pfad zu Itemprofile angeben\n",
    "    bewertung_path = '../data/Bewertungsmatrix_Bibliona.csv' # TODO: Pfad zu Bewertungsmatrix angeben\n",
    "\n",
    "    ratings_df, test_df, itemprofile_df, bewertung_df = load_all_data(\n",
    "        ratings_path, test_path, itemprofile_path, bewertung_path\n",
    "    )\n",
    "\n",
    "    ratings_df = filter_sparse_users_items(ratings_df)\n",
    "    algo, trainset = train_best_svd_model(ratings_df)\n",
    "    metrics = evaluate_model(algo, test_df, trainset, top_k=10,\n",
    "                             bewertung_df=bewertung_df,\n",
    "                             itemprofile_df=itemprofile_df)\n",
    "    print(\"Evaluation Results:\", metrics)\n",
    "\n",
    "    example_user = 243 # TODO: Hier kann die Nutzer-ID für einen beliebigen Nutzer gesetzt werden\n",
    "    recommendations = get_top_n_recommendations(\n",
    "        algo, trainset, example_user, 10, bewertung_df, itemprofile_df\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTop 10 recommendations for user {example_user}:\")\n",
    "    for item_id, score, confidence, explanation, book_metadata in recommendations:\n",
    "        publication_year = book_metadata['Publication_Year']\n",
    "        publication_year_int: int = int(publication_year) if not pd.isnull(publication_year) else None\n",
    "        print(f\"Item ID: {item_id}, Score: {score:.2f}, Confidence: {confidence}\")\n",
    "        print(f\"   Title: {book_metadata['Book-Title']}\")\n",
    "        print(f\"   Year: {publication_year_int}, Publisher: {book_metadata['Publisher']}\")\n",
    "        print(f\"   → Explain: {explanation}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_user_rating_distribution(user_id: int, ratings_df: pd.DataFrame, itemprofile_df: pd.DataFrame) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Analyze the rating distribution for a specific user.\n",
    "    \"\"\"\n",
    "    # Get user's ratings from the ratings matrix\n",
    "    user_ratings_row = ratings_df[ratings_df['user_ID'] == user_id]\n",
    "    \n",
    "    if user_ratings_row.empty:\n",
    "        return {\"error\": f\"User {user_id} not found in ratings data\"}\n",
    "    \n",
    "    # Get all non-null ratings for this user\n",
    "    ratings_data = user_ratings_row.drop(columns=['user_ID']).squeeze()\n",
    "    non_null_ratings = ratings_data.dropna()\n",
    "    \n",
    "    # Count ratings by star level\n",
    "    rating_counts = non_null_ratings.value_counts().sort_index()\n",
    "    \n",
    "    # Get total number of ratings\n",
    "    total_ratings = len(non_null_ratings)\n",
    "    \n",
    "    # Calculate average rating\n",
    "    average_rating = non_null_ratings.mean()\n",
    "    \n",
    "    # Get the actual books rated with their titles\n",
    "    rated_books = []\n",
    "    for item_id, rating in non_null_ratings.items():\n",
    "        book_info = itemprofile_df[itemprofile_df['item_ID'] == item_id]\n",
    "        if not book_info.empty:\n",
    "            title = book_info.iloc[0].get('Book-Title', 'Unknown')\n",
    "            rated_books.append({\n",
    "                'item_ID': item_id,\n",
    "                'title': title,\n",
    "                'rating': rating\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        'user_id': user_id,\n",
    "        'total_ratings': total_ratings,\n",
    "        'average_rating': round(average_rating, 2),\n",
    "        'rating_distribution': rating_counts.to_dict(),\n",
    "        'rated_books': sorted(rated_books, key=lambda x: x['rating'], reverse=True)\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_user_preferences(user_id: int, ratings_df: pd.DataFrame, itemprofile_df: pd.DataFrame) -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Analyze user's author and genre preferences based on their ratings.\n",
    "    \"\"\"\n",
    "    # Get user's ratings\n",
    "    user_ratings_row = ratings_df[ratings_df['user_ID'] == user_id]\n",
    "    \n",
    "    if user_ratings_row.empty:\n",
    "        return {\"error\": f\"User {user_id} not found in ratings data\"}\n",
    "    \n",
    "    # Get all non-null ratings for this user\n",
    "    ratings_data = user_ratings_row.drop(columns=['user_ID']).squeeze()\n",
    "    non_null_ratings = ratings_data.dropna()\n",
    "    \n",
    "    # Initialize counters\n",
    "    author_ratings = {}\n",
    "    genre_ratings = {}\n",
    "    \n",
    "    # Analyze each rated book\n",
    "    for item_id, rating in non_null_ratings.items():\n",
    "        book_info = itemprofile_df[itemprofile_df['item_ID'] == item_id]\n",
    "        \n",
    "        if not book_info.empty:\n",
    "            book_row = book_info.iloc[0]\n",
    "            \n",
    "            # Get authors (columns starting with 'Author_')\n",
    "            author_columns = [col for col in itemprofile_df.columns if col.startswith('Author_')]\n",
    "            for author_col in author_columns:\n",
    "                if book_row[author_col] == 1:\n",
    "                    author_name = author_col.replace('Author_', '')\n",
    "                    if author_name not in author_ratings:\n",
    "                        author_ratings[author_name] = {'total_rating': 0, 'count': 0}\n",
    "                    author_ratings[author_name]['total_rating'] += rating\n",
    "                    author_ratings[author_name]['count'] += 1\n",
    "            \n",
    "            # Get genres (columns starting with 'Genre_')\n",
    "            genre_columns = [col for col in itemprofile_df.columns if col.startswith('Genre_')]\n",
    "            for genre_col in genre_columns:\n",
    "                if book_row[genre_col] == 1:\n",
    "                    genre_name = genre_col.replace('Genre_', '')\n",
    "                    if genre_name not in genre_ratings:\n",
    "                        genre_ratings[genre_name] = {'total_rating': 0, 'count': 0}\n",
    "                    genre_ratings[genre_name]['total_rating'] += rating\n",
    "                    genre_ratings[genre_name]['count'] += 1\n",
    "    \n",
    "    # Calculate average ratings and sort by preference\n",
    "    author_preferences = []\n",
    "    for author, data in author_ratings.items():\n",
    "        avg_rating = data['total_rating'] / data['count']\n",
    "        author_preferences.append({\n",
    "            'author': author,\n",
    "            'average_rating': round(avg_rating, 2),\n",
    "            'books_rated': data['count']\n",
    "        })\n",
    "    author_preferences.sort(key=lambda x: x['average_rating'], reverse=True)\n",
    "    \n",
    "    genre_preferences = []\n",
    "    for genre, data in genre_ratings.items():\n",
    "        avg_rating = data['total_rating'] / data['count']\n",
    "        genre_preferences.append({\n",
    "            'genre': genre,\n",
    "            'average_rating': round(avg_rating, 2),\n",
    "            'books_rated': data['count']\n",
    "        })\n",
    "    genre_preferences.sort(key=lambda x: x['average_rating'], reverse=True)\n",
    "    \n",
    "    return {\n",
    "        'user_id': user_id,\n",
    "        'author_preferences': author_preferences[:10],  # Top 10 authors\n",
    "        'genre_preferences': genre_preferences[:10]     # Top 10 genres\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 243 Rating Analysis\n",
      "User 243 has rated 10 books\n",
      "Average rating: 7.9\n",
      "\n",
      "Rating distribution:\n",
      "  5.0 points: 1 books\n",
      "  6.0 points: 1 books\n",
      "  7.0 points: 3 books\n",
      "  9.0 points: 3 books\n",
      "  10.0 points: 2 books\n",
      "\n",
      "Top 5 rated books:\n",
      "  1. The Bean Trees - 10.0 points\n",
      "  2. Memoirs of a Geisha - 10.0 points\n",
      "  3. The Pilot's Wife : A Novel - 9.0 points\n",
      "  4. Unnatural Exposure - 9.0 points\n",
      "  5. The General's Daughter - 9.0 points\n",
      "\n",
      "=== User 243 Preferences Analysis ===\n",
      "Top 5 Authors (by average rating):\n",
      "  1. Barbara Kingsolver - 10.0 points (1 books)\n",
      "  2. Arthur Golden - 10.0 points (1 books)\n",
      "  3. Anita Shreve - 9.0 points (1 books)\n",
      "  4. Patricia Cornwell - 9.0 points (1 books)\n",
      "  5. Nelson De Mille - 9.0 points (1 books)\n",
      "\n",
      "Top 5 Genres (by average rating):\n",
      "  1. Fiction, coming of age - 10.0 points (1 books)\n",
      "  2. Fiction, humorous, general - 10.0 points (1 books)\n",
      "  3. Friendship - 10.0 points (1 books)\n",
      "  4. Friendship, fiction - 10.0 points (1 books)\n",
      "  5. Literature - 10.0 points (2 books)\n"
     ]
    }
   ],
   "source": [
    "# Test the new functions for user 243\n",
    "print(\"User 243 Rating Analysis\")\n",
    "rating_analysis = analyze_user_rating_distribution(243, ratings_df, itemprofile_df)\n",
    "if 'error' not in rating_analysis:\n",
    "    print(f\"User {rating_analysis['user_id']} has rated {rating_analysis['total_ratings']} books\")\n",
    "    print(f\"Average rating: {rating_analysis['average_rating']}\")\n",
    "    print(\"\\nRating distribution:\")\n",
    "    for stars, count in rating_analysis['rating_distribution'].items():\n",
    "        print(f\"  {stars} points: {count} books\")\n",
    "    \n",
    "    print(f\"\\nTop 5 rated books:\")\n",
    "    for i, book in enumerate(rating_analysis['rated_books'][:5]):\n",
    "        print(f\"  {i+1}. {book['title']} - {book['rating']} points\")\n",
    "\n",
    "print(\"\\n=== User 243 Preferences Analysis ===\")\n",
    "preferences_analysis = analyze_user_preferences(243, ratings_df, itemprofile_df)\n",
    "if 'error' not in preferences_analysis:\n",
    "    print(\"Top 5 Authors (by average rating):\")\n",
    "    for i, author in enumerate(preferences_analysis['author_preferences'][:5]):\n",
    "        print(f\"  {i+1}. {author['author']} - {author['average_rating']} points ({author['books_rated']} books)\")\n",
    "    \n",
    "    print(\"\\nTop 5 Genres (by average rating):\")\n",
    "    for i, genre in enumerate(preferences_analysis['genre_preferences'][:5]):\n",
    "        print(f\"  {i+1}. {genre['genre']} - {genre['average_rating']} points ({genre['books_rated']} books)\")\n",
    "else:\n",
    "    print(preferences_analysis['error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bewertung & Beispielausgabe**\n",
    "\n",
    "Die Evaluierung des SVD-Modells zeigt solide RMSE- und MAE-Werte, allerdings fällt die Precision@K mit 0.0035 und die Recall@K mit 0.0214 eher schwach aus. Das liegt vermutlich an der hohen Item-Vielfalt und sparsamen Nutzer-Item-Matrix, wodurch relevante Empfehlungen schwerer zu treffen sind.\n",
    "\n",
    "Als Beispiel zeigt die Ausgabe für Nutzer 243 zehn Top-Empfehlungen mit hoher Konfidenz. Neben der reinen Score-Normalisierung (0–1) wird jede Empfehlung durch eine einfache \"Explainability\"-Komponente ergänzt: Die finale Vorhersage ergibt sich aus dem globalen Durchschnitt, dem Nutzer-Bias, dem Item-Bias sowie der latenten Interaktion zwischen Nutzer- und Item-Vektor. Dadurch lassen sich Vorhersagen transparenter nachvollziehen, z. B. ob sie eher durch starke Item-Beliebtheit oder durch ein hohes Matching-Profil zwischen Nutzer und Item beeinflusst sind."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
